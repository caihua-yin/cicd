# Vagrant Boxes
Run following commands to prepare dev and prod environments:
- `vagrant up dev --provision`: start and provision dev machine
- `vagrant up prod01 prod02 prod03`: start three prod machines

## NOTE
To run elasticsearch in prod02, the *vm.max_map_count* system parameter has been tuned as `sysctl -w vm.max_map_count=655360` (/etc/sysctl.conf also updated). This is manually updated currently. It can be handled by vagrant provision script later.

# Ansible Playbooks
Run following commands on dev node (CWD as /vagrant/github.com/caihua-yin/cicd/ansible/)

## Deploy Cloud By One Command
`ansible-playbook yinc2-cloud.yml -i inventory/prod`

The playbook *yinc2-cloud.yml* is generated by concatenating following separate playbooks by category. The separate playbooks need run with order in sequence, as the latter ones will depend on the former ones

`cat common-dependency.yml service-registry-discovery-config-mgmt.yml app.yml reverse-proxy-lb.yml logging.yml monitoring.yml > yinc2-cloud.yml`

## Common Dependency
`ansible-playbook common-dependency.yml -i inventory/prod`
- Install common dependencies to each node in the cluster
    - jq
    - docker
        - Docker UI on every node: http://192.168.33.21:9000

## Service Registry-Discovery And Configuration Management
`ansible-playbook service-registry-discovery-config-mgmt.yml -i inventory/prod`
- Deploy consul for service discovery and configuration key-value store
    - http://192.168.33.21:8500/ui: consul GUI
- Deploy registrator for service auto registry
- Deploy consul-template for configuration update
### Alternative solution
`ansible-playbook service-registry-discovery-config-mgmt-alternative.yml -i inventory/prod`
- Deploy etcd for configuration key-value store (service discovery will also use the key-value store)
- Deploy registrator for service auto registry
- Deploy confd for configuration update

## Applications
`ansible-playbook app.yml -i inventory/prod`
- Deploy fibonacci service to each node in the cluster
- Deploy store service to each node in the cluster

## Databases (not included in yinc2-cloud by default)
`ansible-playbook postgresql.yml -i inventory/prod`
- Deploy PostgreSQL to prod01
`ansible-playbook cassandra.yml -i inventory/prod`
- Deploy Cassandra cluster to each node in the cluster
- With prod01 as seed node

## Reverse Proxy and Load Balancing
`ansible-playbook reverse-proxy-lb.yml -i inventory/prod`
- Deploy nginx for reverse proxy and load balancing
### Alernative solution to use HAProxy
`ansible-playbook reverse-proxy-lb-alternative.yml -i inventory/prod`
- Deploy HAProxy for reverse proxy and load balancing (Use port 8000 to avoid conflict with nginx)

## Logging and Monitoring
`ansible-playbook logging.yml -i inventory/prod`
- Deploy elasticsearch for logging message store
- Deploy logstash for logging message collection, filtering, and persistence to elasticsearch
- Deploy fluentd for logging message collection, filtering, and persistence to elasticsearch
- Deploy kibana for logging message visualization and analysis
    - http://192.168.33.22:5601

## Monitoring And Alerting
`ansible-playbook monitoring.yml -i inventory/prod`
- Deploy influxdb for time series monitoring metric store
    - http://192.168.33.21:8083 for influxdb admin portal
- Deploy collectd for metric collection in each cluster node
- Deploy statsite (replacement of statsd) for application sent metric aggregation (write to influxdb)
    - Run `while true; do echo "api:$(($RANDOM%100))|ms" | nc -u -w0 127.0.0.1 8125; sleep 1; done` at 192.168.33.21 to send fictional API latency metric to statsd.
- Deploy grafana for monitoring metric visualization (read from influxdb)
    - http://192.168.33.21:3000 for grafana GUI
    - The alerting feature can be manually configured via grafana GUI

## Ambry
`ansible-playbook ambry.yml -i inventory/prod --tags ambry-setup`
- Deploy Ambry in a three-node cluster, each node with two disks
- Totally two partitions are allocated, each partition with three replicas
- Both datanode and frontend service are deployed

`ansible-playbook ambry.yml -i inventory/prod --tags ambry-stop`
- Stop datanode and frontend services

`ansible-playbook ambry.yml -i inventory/prod --tags ambry-cleanup`
- Cleanup the ambry stuff in the environment

# Post-deployment Testing
Run `docker run -e "ENDPOINT=http://192.168.33.22" yinc2/post-deplopment-test:latest` in dev machine for post deplopment testing.
*TODO:* Manage by ansible playbook??

# Manual Test
Use following commands to send request to specific app:
- Fibonacci: `curl http://localhost:8888/fibonacci/5`
- Store:
    - `curl -XPOST http://localhost:8001/store/items -H "Content-Type: application/json" -d '{"brand":"apple", "name":"iPhone7", "description":"The latest iphone"}'`
    - `curl http://localhost:8001/store/items/d9494812-6154-4ac6-9177-5e6ee3eb648b`

To use proxy, replace port as follows:
- nginx: 80
- haproxy: 8000

# TODO
- use grafana API to auto create data source and dashboard
- use random port for store and fibonacci
- explore visualization, dashboard and alerting (?) in kibana
- make app send structured log proactively to fluentd/logstash/ES ingestion node?
